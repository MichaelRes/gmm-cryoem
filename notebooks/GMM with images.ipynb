{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import sys\n",
    "sys.path.append('../src/')\n",
    "from forward_modeling import project_volume, slice_volume\n",
    "from molecular_handling import particle\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmm_image_dataset(particles,size=100,noise=0.1,size_grid=32):\n",
    "    \"\"\"\n",
    "    This function creates a dataet of images of a set of particles: \n",
    "    for each image, we randomly choose one of the particle of the set, rotate it along the z axis, and add some noise.\n",
    "    \n",
    "        Arguments:\n",
    "        ---------\n",
    "        - particles (list): \n",
    "            list of the different particles in the dataset\n",
    "        - size (int {default:100}): \n",
    "            lentgh of the dataset\n",
    "        - noise (float {default: 0.1}):\n",
    "            noise added to the images\n",
    "        - size_grid (integer {default:32}):\n",
    "            number of voxels along each grid direction\n",
    "    \"\"\"\n",
    "    dataset = np.zeros((size, size_grid, size_grid))\n",
    "    n_particles = len(particles)\n",
    "    for t in range(size):\n",
    "        iat = np.random.randint(n_particles)\n",
    "        angle = np.random.rand() * 360\n",
    "        rot = R.from_euler('z', angle, degrees = True)\n",
    "        \n",
    "        particles[iat].rotate(quat = rot.as_quat())\n",
    "        dataset[t,:,:] = particles[iat].image\n",
    "    \n",
    "    return dataset + np.random.randn(dataset.shape[0], dataset.shape[1], dataset.shape[2])*noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "particle1 = particle(n_atom=4, rads_atom=[1.,1.,1.,1.], size_grid = 32)\n",
    "particle2 = particle(n_atom=2, rads_atom=[2.,2.], size_grid = 32)\n",
    "particle3 = particle(n_atom=1, rads_atom=[3.], size_grid = 32)\n",
    "particles = [particle1, particle2, particle3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = gmm_image_dataset(particles, noise=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple gaussian mixture model applied directly to the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we simply train a gaussian mixture model on the dataset, and compare the images of the particles, and the means of the gaussians of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_dataset = dataset.reshape(100,1024)\n",
    "gm = GaussianMixture(3)\n",
    "gm.fit(reshaped_dataset)\n",
    "\n",
    "images = gm.means_.reshape(3,32,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(particle1.image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(particle2.image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(particle3.image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It worked quite good without having to find the orientations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marginalizing over the orientations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we built an algorithm that reconstruct the images of the particles, by marginalizing over the orientations. In this approach, we treat the heterogeneity as in Relion, by assuming that all particles comes from a finite number of conformations. \n",
    "\n",
    "Let use the following notations:\n",
    "- $(X)_i$ the image dataset, containing rotation of a finite number of particle images, with noise added.\n",
    "- $(\\theta)_j$ a set of orientations (regularly sampled between 0 and 360 degrees)\n",
    "- $R_\\theta (X_i)$ the rotation of $X_i$ by angle $\\theta$ \n",
    "- $(I)_k^{(t)}$ a finite set of images representing the particle images at iteration t (the number of conformations we are looking for)\n",
    "\n",
    "We first need to define a probability score telling us how close are two images: \n",
    "\n",
    "$$P(X,I) = \\prod_{l} P(N >|X_l - I_l|)$$ \n",
    "with $N$ a zero mean gaussian (the scale will be chosen afterward)\n",
    "This probability score is more efficient than the version where we would have used the density function instead, because it tends to lead to either a score of 0 of a score of inf.\n",
    "\n",
    "At iteration t, the reconstruction function does at follows:\n",
    "\n",
    "$$(I)_k^{(t+1)} =\\frac{\\sum_{i} \\sum_{j} P((I)_k^{(t)}, R_{\\theta_j} (X_i))R_{\\theta_j} (X_i)}{\\sum_{i} \\sum_{j} P((I)_k^{(t)}, R_{\\theta_j} (X_i))} $$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rot_mat(theta):\n",
    "    \"\"\"\n",
    "    This function builds a rotation matrix of angle theta\n",
    "    \"\"\"\n",
    "    #theta in radians\n",
    "    c, s = np.cos(theta), np.sin(theta)\n",
    "    mat = np.array(((c, -s), (s, c)))\n",
    "    return mat\n",
    "    \n",
    "\n",
    "def rotate_image(image, theta):\n",
    "    \"\"\"\n",
    "    This function rotates the image by an angle theta\n",
    "    \"\"\"\n",
    "    rot = rot_mat(theta)\n",
    "    N = image.shape[0]\n",
    "    rot_image = np.zeros((N,N))\n",
    "    x = np.linspace(-1,1,N)\n",
    "    y = np.linspace(-1,1,N)\n",
    "    interpolating_function = RegularGridInterpolator((x,y), image)\n",
    "\n",
    "    for i in range(N):\n",
    "        x = -1 + i*2/(N-1)\n",
    "        for j in range(N):\n",
    "            y = -1 + j*2/(N-1)\n",
    "            vect = np.array((x,y))\n",
    "            vect_ = rot @ vect\n",
    "            if np.max(np.abs(vect_))<=1:\n",
    "                rot_image[i,j] += interpolating_function(vect_)\n",
    "                \n",
    "    return rot_image\n",
    "\n",
    "def proba(model, rotated_image):\n",
    "    \"\"\"\n",
    "    This function calculates a probability score to tell how close two images are.\n",
    "    \"\"\"\n",
    "    prob = 1\n",
    "    for i in range(rotated_image.shape[0]):\n",
    "        for j in range(rotated_image.shape[1]):\n",
    "            prob*=(1 - norm.cdf(np.abs(model[i,j]-rotated_image[i,j]), loc = 0, scale = 1))*2\n",
    "    return prob\n",
    "\n",
    "def reconstruct(dataset, models, theta_step):\n",
    "    \"\"\"\n",
    "    This function reconstructs the models at step t+1 given the models at step t\n",
    "    To long, probably need to be optimize\n",
    "    \"\"\"\n",
    "    thetas = np.linspace(0,360,theta_step)\n",
    "    next_models = np.zeros(models.shape)\n",
    "    probs = np.zeros((models.shape[0]))\n",
    "    for i in range(len(dataset)):\n",
    "        if (i+1)%10 == 0:\n",
    "            print(i+1)\n",
    "        for j in range(len(thetas)):\n",
    "            rotated_image = rotate_image(dataset[i], thetas[j])\n",
    "            for k in range(models.shape[0]):\n",
    "                prob = proba(models[k], rotated_image)\n",
    "                probs[k]+= prob\n",
    "                next_models[k] += prob * rotated_image #we add the image, weighed by the probabity\n",
    "                                                        #to construct the models at the next iteration\n",
    "                \n",
    "    for k in range(models.shape[0]):\n",
    "        next_models[k]/probs[k]\n",
    "        \n",
    "    return next_models\n",
    "\n",
    "def EM(dataset, models_init, eps=1, n_steps=10, theta_step=10):\n",
    "    \"\"\"\n",
    "    This function iterates the reconstruct function to converge to a local optimum\n",
    "    \"\"\"\n",
    "    models = models_init\n",
    "    step = 0\n",
    "    end = False\n",
    "    while step<n_steps and not(end):\n",
    "        print('step:' +str(step+1))\n",
    "        next_models = reconstruct(dataset, models, theta_step)\n",
    "        step +=1\n",
    "        if np.sum(np.abs(next_models - models)) < eps:\n",
    "            end = True\n",
    "        else:\n",
    "            models = next_models\n",
    "    \n",
    "    return next_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = EM(dataset, images,n_steps = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(final_model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(final_model[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(final_model[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
